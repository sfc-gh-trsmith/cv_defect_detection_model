{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27a47a7-54ad-4866-b16c-90933a17a9f2",
   "metadata": {
    "collapsed": false,
    "name": "Title"
   },
   "source": [
    "# Multiclass Defect Detection with Distributed training using PyTorch Object Detection Models in Snowflake Notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc94dc00-422d-423d-bf6c-cbfe8ef7a175",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "headers"
   },
   "outputs": [],
   "source": [
    "!pip freeze | grep snow\n",
    "!pip install opencv-python-headless\n",
    "\n",
    "session = get_active_session()\n",
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c1be8-b51c-44b5-b769-5f7fcd16feb1",
   "metadata": {
    "collapsed": false,
    "name": "mk1"
   },
   "source": [
    "## Install necessary packages:\n",
    "\n",
    "* torch\n",
    "* torchvision\n",
    "* opencv\n",
    "* matplotlib\n",
    "* Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c23e35-93ed-4665-afb2-4614e504827c",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "installcv"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!apt update && apt install -y libsm6 libxext6\n",
    "!apt-get install -y libxrender-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33097ff5-5bfe-49dd-a147-7e3b962919e6",
   "metadata": {
    "collapsed": false,
    "name": "mk2"
   },
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Importheader"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark import types as T\n",
    "\n",
    "from snowflake.ml.modeling.distributors.pytorch import PyTorchDistributor, PyTorchScalingConfig, WorkerResourceConfig\n",
    "from snowflake.ml.data.sharded_data_connector import ShardedDataConnector\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "session.query_tag = {\"origin\":\"sf_sit-is\", \n",
    "                     \"name\":\"distributed_ml_crt_imageanomaly_detection\", \n",
    "                     \"version\":{\"major\":1, \"minor\":0,},\n",
    "                     \"attributes\":{\"is_quickstart\":1, \"source\":\"notebook\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a9b6a-bdd6-40d5-bcb8-d101ed04df44",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "devices"
   },
   "outputs": [],
   "source": [
    "# The NVIDIA A10G is a professional GPU designed for data center workloads, such as AI inference, virtual desktops\n",
    "#  (VDI), and professional graphics. It's based on the NVIDIA Ampere architecture and features 24 GB of GDDR6\n",
    "#  memory, 80 RT Cores, and 320 third-generation Tensor Cores, delivering up to 250 TOPS of compute power for AI. \n",
    "# Key features include its 300W power envelope, single-slot form factor, and versatility in handling both \n",
    "# graphically intensive and AI-accelerated applications. \n",
    "\n",
    "# Get device info\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(\"Number of GPU devices available:\", num_gpus)\n",
    "    \n",
    "    for i in range(num_gpus):\n",
    "        print(\"Device\", i, \":\", torch.cuda.get_device_name(i))\n",
    "    \n",
    "    #Set a default device\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    print(\"CUDA is not available. Check your installation or GPU setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data_stage contains the PCB images loaded in the /images subfolder and the labels loaded in the /labels subfolder\n",
    "session.sql(\"ls @data_stage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250bed13-6cfd-4ff5-bb59-84894d62c9c2",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": [
    "### View the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84721d-d9ba-44ed-b5db-db91fd69c382",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Dataset_sample"
   },
   "outputs": [],
   "source": [
    "session.table(\"training_data\").limit(5).collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afef197-07d0-41b5-b485-7f5fd32a0a63",
   "metadata": {
    "collapsed": false,
    "name": "Train_heading"
   },
   "source": [
    "# # Distributed Model Training\n",
    "# \n",
    "# This section demonstrates how to train a Faster R-CNN object detection model using Snowflake's distributed training capabilities. The training process leverages multiple GPU workers in parallel to accelerate model training on the PCB defect detection dataset.\n",
    "# \n",
    "# ## Step 1: Define a Training Function for Each Worker\n",
    "# \n",
    "# We create a `train_func()` that encapsulates the complete training logic for a single worker. This function will:\n",
    "# - Initialize the distributed training environment and establish communication between workers\n",
    "# - Load and preprocess the training data from Snowflake tables\n",
    "# - Create a custom PyTorch Dataset that decodes base64-encoded images and prepares bounding box annotations\n",
    "# - Initialize the Faster R-CNN model with a custom classifier head for our specific number of defect classes\n",
    "# - Wrap the model in DistributedDataParallel (DDP) to enable gradient synchronization across workers\n",
    "# - Execute the training loop with forward pass, loss calculation, backpropagation, and optimizer updates\n",
    "# - Save the trained model weights to a Snowflake stage for later inference\n",
    "# \n",
    "# Each worker executes this function independently on its assigned data shard, with PyTorch's distributed training framework coordinating gradient updates across all workers.\n",
    "# \n",
    "# ## Step 2: Execute the Training Function Using PyTorchDistributor\n",
    "# \n",
    "# The `PyTorchDistributor` is Snowflake's orchestration layer that manages the distributed training job. It handles:\n",
    "# - Provisioning GPU compute resources from the specified compute pool\n",
    "# - Distributing the training function code to all workers\n",
    "# - Coordinating the initialization and synchronization of the distributed training process\n",
    "# - Monitoring worker health and handling failures\n",
    "# - Collecting results and logs from all workers\n",
    "# \n",
    "# Key components of the distributed training configuration:\n",
    "# \n",
    "# * **ShardedDataConnector**: Automatically partitions the training dataset into non-overlapping shards, with each worker receiving a unique subset of the data. This ensures:\n",
    "#   - No data duplication across workers (each image is processed by exactly one worker per epoch)\n",
    "#   - Balanced workload distribution for optimal GPU utilization\n",
    "#   - Efficient data loading directly from Snowflake tables without manual partitioning logic\n",
    "# \n",
    "# * **PyTorchScalingConfig**: Defines the distributed training cluster topology and resource allocation:\n",
    "#   - `num_workers`: Number of parallel training processes (typically matches the number of available GPUs)\n",
    "#   - `num_cpus_per_worker`: CPU cores allocated to each worker for data preprocessing and loading\n",
    "#   - `num_gpus_per_worker`: GPUs assigned to each worker (usually 1 GPU per worker for optimal performance)\n",
    "#   - `memory_per_worker`: RAM allocated per worker for caching data and model states\n",
    "#   - These settings directly impact training speed, memory usage, and cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883e4b4-8058-4b36-82c1-cfde8ef54a26",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Train_function"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# IMPORTS: Required libraries for distributed training\n",
    "# ==============================================================================\n",
    "import base64  # For decoding base64-encoded image data from Snowflake\n",
    "import io  # For handling in-memory byte streams\n",
    "import cv2  # OpenCV for advanced image processing (if needed)\n",
    "import torch  # PyTorch deep learning framework\n",
    "import numpy as np  # Numerical computing library\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset  # Data loading utilities\n",
    "from PIL import Image  # Python Imaging Library for image manipulation\n",
    "import torchvision  # Computer vision utilities and models\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn  # Pretrained Faster R-CNN model\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor  # Classifier head for Faster R-CNN\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights  # Pretrained weights\n",
    "import torch.distributed as dist  # PyTorch distributed training utilities\n",
    "from snowflake.ml.modeling.distributors.pytorch import get_context  # Snowflake distributed context\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP  # Distributed Data Parallel wrapper\n",
    "import tempfile  # For creating temporary files/directories\n",
    "import cloudpickle as cp  # Enhanced pickling for Python objects\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN TRAINING FUNCTION: Executed by each worker in distributed training\n",
    "# ==============================================================================\n",
    "def train_func():\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # DISTRIBUTED TRAINING SETUP\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # Get the distributed training context from Snowflake\n",
    "    context = get_context()\n",
    "    \n",
    "    # Get this worker's rank (unique ID) in the distributed training cluster\n",
    "    rank = context.get_rank()\n",
    "    \n",
    "    # Initialize the process group for distributed training using NCCL backend\n",
    "    # NCCL (NVIDIA Collective Communications Library) is optimized for GPU communication\n",
    "    dist.init_process_group(backend=\"nccl\")\n",
    "    \n",
    "    # Print worker information for debugging\n",
    "    print(f\"Worker Rank : {rank}, world_size: {context.get_world_size()}\")\n",
    "\n",
    "    # ==============================================================================\n",
    "    # CUSTOM DATASET CLASS: Transforms Snowflake data for PyTorch training\n",
    "    # ==============================================================================\n",
    "    class FCBData(IterableDataset):\n",
    "        \"\"\"\n",
    "        Custom PyTorch IterableDataset for PCB defect detection.\n",
    "        Decodes base64 images from Snowflake and prepares targets for Faster R-CNN.\n",
    "        \"\"\"\n",
    "        def __init__(self, source_dataset, transforms=None):  \n",
    "            # Store reference to the Snowflake dataset shard\n",
    "            self.source_dataset = source_dataset\n",
    "            \n",
    "            # Set transform pipeline; default to ToTensor if none provided\n",
    "            # ToTensor converts PIL images to PyTorch tensors with shape [C, H, W]\n",
    "            self.transforms = transforms if transforms else torchvision.transforms.ToTensor()\n",
    "    \n",
    "        def __iter__(self):\n",
    "            \"\"\"\n",
    "            Iterator that yields (image, target) pairs for each data row.\n",
    "            \"\"\"\n",
    "            for row in self.source_dataset:\n",
    "                # --------------------------------------------------------------\n",
    "                # IMAGE DECODING: Convert base64 string to PIL Image\n",
    "                # --------------------------------------------------------------\n",
    "                base64_image = row['IMAGE_DATA']\n",
    "                # Decode base64 string -> bytes -> PIL Image\n",
    "                image = Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "                \n",
    "                # Apply transformations (converts PIL Image to tensor)\n",
    "                image = self.transforms(image)\n",
    "    \n",
    "                # --------------------------------------------------------------\n",
    "                # TARGET PREPARATION: Extract bounding boxes and class labels\n",
    "                # --------------------------------------------------------------\n",
    "                # Extract bounding box coordinates [xmin, ymin, xmax, ymax]\n",
    "                # Format: [[xmin, ymin, xmax, ymax]] for a single detection per image\n",
    "                boxes = [[row[k].item() for k in [\"XMIN\", \"YMIN\", \"XMAX\", \"YMAX\"]] for _ in range(1)]\n",
    "                \n",
    "                # Extract class label (defect type: open, short, mousebite, etc.)\n",
    "                labels = [row[\"CLASS\"].item()]\n",
    "    \n",
    "                # Convert to PyTorch tensors with appropriate dtypes\n",
    "                boxes = torch.as_tensor(boxes, dtype=torch.float32)  \n",
    "                labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "                \n",
    "                # --------------------------------------------------------------\n",
    "                # TARGET DICTIONARY: Format required by Faster R-CNN\n",
    "                # --------------------------------------------------------------\n",
    "                target = {  \n",
    "                    'boxes': boxes,  # Bounding box coordinates [N, 4]\n",
    "                    'labels': labels,  # Class labels [N]\n",
    "                    'image_id': torch.tensor([int(row[\"FILENAME\"])]),  # Unique image identifier\n",
    "                    'area': (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1]),  # Box area (width * height)\n",
    "                    'iscrowd': torch.zeros((boxes.shape[0],), dtype=torch.uint8)  # 0 = single object, 1 = crowd\n",
    "                }\n",
    "                \n",
    "                # Yield (image, target) pair for this sample\n",
    "                yield (image, target)\n",
    "\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # GPU CONTEXT: Set the GPU device for this worker\n",
    "    # ------------------------------------------------------------------------------\n",
    "    with torch.cuda.device(rank):\n",
    "        # ==============================================================================\n",
    "        # MODEL INITIALIZATION: Load pretrained Faster R-CNN and customize for PCB defects\n",
    "        # ==============================================================================\n",
    "        # Load pretrained Faster R-CNN with ResNet50 backbone and Feature Pyramid Network\n",
    "        weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT  \n",
    "        model = fasterrcnn_resnet50_fpn(weights=weights)\n",
    "          \n",
    "        # ------------------------------------------------------------------------------\n",
    "        # CLASSIFIER HEAD MODIFICATION: Adapt for custom number of defect classes\n",
    "        # ------------------------------------------------------------------------------\n",
    "        # Set number of classes (background + 6 defect types)\n",
    "        num_classes = 7\n",
    "        \n",
    "        # Get the number of input features to the classification head\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features  \n",
    "        \n",
    "        # Replace the pretrained predictor with a new one for our custom classes\n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "        \n",
    "        # Move model to the GPU assigned to this worker\n",
    "        model.to(rank)\n",
    "        \n",
    "        # Wrap model with DistributedDataParallel for multi-GPU training\n",
    "        # DDP synchronizes gradients across all workers during backpropagation\n",
    "        model = DDP(model, device_ids=[rank])\n",
    "        \n",
    "        # ==============================================================================\n",
    "        # OPTIMIZER AND SCHEDULER: Configure training optimization\n",
    "        # ==============================================================================\n",
    "        # Adam optimizer with weight decay for regularization\n",
    "        # Only optimize parameters that require gradients\n",
    "        optimizer = torch.optim.Adam(\n",
    "            [p for p in model.parameters() if p.requires_grad], \n",
    "            lr=0.0001,  # Learning rate\n",
    "            weight_decay=0.0005  # L2 regularization\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduler: reduce LR by factor of 0.1 every 3 epochs\n",
    "        # Helps model converge to better local minima\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    \n",
    "        # ==============================================================================\n",
    "        # DATA LOADING: Prepare distributed dataset and dataloader\n",
    "        # ==============================================================================\n",
    "        # Get the dataset map from Snowflake's distributed context\n",
    "        dataset_map = context.get_dataset_map()\n",
    "        \n",
    "        # Get this worker's shard of the training data\n",
    "        # ShardedDataConnector automatically partitions data across workers\n",
    "        train_shard = dataset_map[\"train\"].get_shard().to_torch_dataset()\n",
    "        \n",
    "        # Wrap the shard with our custom dataset class\n",
    "        train_dataset = FCBData(train_shard)\n",
    "    \n",
    "        # Get hyperparameters passed from the PyTorchDistributor\n",
    "        hyper_parms = context.get_hyper_params()\n",
    "        \n",
    "        # ------------------------------------------------------------------------------\n",
    "        # COLLATE FUNCTION: Custom batch collation for variable-sized inputs\n",
    "        # ------------------------------------------------------------------------------\n",
    "        def collate_fn(batch):\n",
    "            \"\"\"\n",
    "            Custom collate function for Faster R-CNN.\n",
    "            Object detection models accept lists of images and targets,\n",
    "            not batched tensors (since images may have different sizes).\n",
    "            \"\"\"\n",
    "            return tuple(zip(*batch))\n",
    "    \n",
    "        # Extract batch size from hyperparameters\n",
    "        batch_size = int(hyper_parms['batch_size'])\n",
    "        \n",
    "        # Create DataLoader for efficient batch loading\n",
    "        train_data_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,  # Shuffling handled by ShardedDataConnector\n",
    "            collate_fn=collate_fn,  # Use custom collation\n",
    "            pin_memory=True,  # Pin memory for faster GPU transfer\n",
    "            pin_memory_device=f\"cuda:{rank}\"  # Pin to this worker's GPU\n",
    "        )\n",
    "\n",
    "        # ==============================================================================\n",
    "        # TRAINING LOOP: Train the model for specified number of epochs\n",
    "        # ==============================================================================\n",
    "        num_epochs = int(hyper_parms['num_epochs'])\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Set model to training mode (enables dropout, batch norm training, etc.)\n",
    "            model.train()\n",
    "            \n",
    "            # Initialize metrics for this epoch\n",
    "            running_loss = 0.0\n",
    "            running_batches = 0\n",
    "            \n",
    "            # ------------------------------------------------------------------------------\n",
    "            # BATCH ITERATION: Process each batch of images and targets\n",
    "            # ------------------------------------------------------------------------------\n",
    "            for images, targets in train_data_loader:\n",
    "                running_batches = running_batches + 1\n",
    "                \n",
    "                # Normalize images from [0, 255] to [0, 1] range\n",
    "                # Faster R-CNN expects pixel values in [0, 1]\n",
    "                images = [image.float() / 255.0 for image in images]\n",
    "                \n",
    "                # Transfer images to GPU\n",
    "                images = [image.to(rank) for image in images]\n",
    "                \n",
    "                # Transfer all target tensors to GPU\n",
    "                targets = [{k: v.to(rank) for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                # ----------------------------------------------------------------------\n",
    "                # FORWARD PASS: Compute losses\n",
    "                # ----------------------------------------------------------------------\n",
    "                # In training mode, Faster R-CNN returns a dictionary of losses\n",
    "                # (classification loss, box regression loss, RPN losses, etc.)\n",
    "                loss_dict = model(images, targets)\n",
    "                \n",
    "                # Sum all individual losses into a single scalar\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "                \n",
    "                # ----------------------------------------------------------------------\n",
    "                # BACKWARD PASS: Compute gradients and update weights\n",
    "                # ----------------------------------------------------------------------\n",
    "                # Clear gradients from previous iteration\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Compute gradients via backpropagation\n",
    "                losses.backward()\n",
    "                \n",
    "                # Update model parameters using computed gradients\n",
    "                optimizer.step()\n",
    "    \n",
    "                # Accumulate loss for epoch statistics\n",
    "                running_loss += losses.item()\n",
    "    \n",
    "            # Print epoch statistics (loss and images processed)\n",
    "            print(f\"[Rank {rank}] Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / (running_batches*batch_size):.4f}, Processed {running_batches * (epoch+1) * batch_size} images so far\")\n",
    "            \n",
    "            # Step the learning rate scheduler (reduce LR if scheduled)\n",
    "            lr_scheduler.step()\n",
    "    \n",
    "        # ==============================================================================\n",
    "        # MODEL SAVING: Save trained model (only from rank 0 to avoid conflicts)\n",
    "        # ==============================================================================\n",
    "        MODEL_PATH = \"/tmp/models/detectionmodel.pt\"\n",
    "        \n",
    "        if rank == 0:\n",
    "            # Only the primary worker (rank 0) saves the model\n",
    "            # This prevents multiple workers from writing to the same file\n",
    "            with open(MODEL_PATH, mode=\"w+b\") as model_file:\n",
    "                # Save model state dict (weights and biases)\n",
    "                # Use model.module to access the underlying model inside DDP wrapper\n",
    "                torch.save(model.module.state_dict(), model_file)\n",
    "            print(f\"Model written to {MODEL_PATH}\")\n",
    "    \n",
    "        # Training completion message\n",
    "        print(f\"[Rank {rank}] Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a83929-ea61-4d1d-98a0-13637768a4dd",
   "metadata": {
    "collapsed": false,
    "name": "traindataset"
   },
   "source": [
    "### For the purpose of this quickstart, we have considered a smaller volume as the data source. But ideally this can scale million rows\n",
    "\n",
    "1. Split the dataset (shard) for distributed training across multiple workers.\n",
    "2. Train a PyTorch model using 4 workers, each utilizing 1 GPU for efficient computation. Control the training with hyperparameters such as batch size and number of epochs.\n",
    "3. Adjust the number of epochs as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e1ca6-34ac-47b2-9e3a-8295712a99b5",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Train_dataset"
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DISTRIBUTED TRAINING SETUP: Configure PyTorch Distributor for Multi-GPU Training\n",
    "# ==============================================================================\n",
    "\n",
    "# Import required components for distributed PyTorch training in Snowflake\n",
    "from snowflake.ml.modeling.distributors.pytorch import PyTorchDistributor, PyTorchScalingConfig, WorkerResourceConfig  \n",
    "from snowflake.ml.data.sharded_data_connector import ShardedDataConnector  \n",
    "import ray, torch\n",
    "\n",
    "# Initialize Ray cluster if not already running\n",
    "# Ray is used to orchestrate distributed training across multiple workers\n",
    "if not ray.is_initialized(): \n",
    "    ray.init()\n",
    "\n",
    "# Display available cluster resources (should show GPU count)\n",
    "print(ray.cluster_resources())        # should include 'GPU': N\n",
    "\n",
    "# Verify CUDA availability and GPU count for PyTorch\n",
    "print(torch.cuda.is_available(), torch.cuda.device_count())\n",
    "\n",
    "# Load training data from Snowflake table\n",
    "df = session.table(\"training_data\")\n",
    "\n",
    "# Create sharded data connector to distribute data across workers\n",
    "# Each worker will receive a shard (partition) of the training data\n",
    "train_data = ShardedDataConnector.from_dataframe(df)\n",
    "\n",
    "# Configure the PyTorch distributor for distributed training\n",
    "pytorch_trainer = PyTorchDistributor(  \n",
    "    train_func=train_func,  # The training function defined earlier\n",
    "    scaling_config=PyTorchScalingConfig(  \n",
    "        num_nodes=1,  # Number of compute nodes to use\n",
    "        num_workers_per_node=1,  # 4 workers per node for parallel training\n",
    "        # Allocate 1 GPU per worker (4 GPUs total for this configuration)\n",
    "        resource_requirements_per_worker=WorkerResourceConfig(num_cpus=0, num_gpus=1),  \n",
    "    )  \n",
    ")  \n",
    "\n",
    "# Execute distributed training\n",
    "# - dataset_map: Maps the sharded training data to the \"train\" key\n",
    "# - hyper_params: Training hyperparameters (batch size and number of epochs)\n",
    "pytorch_trainer.run(\n",
    "    dataset_map={\"train\": train_data},\n",
    "    hyper_params={\"batch_size\": \"32\", \"num_epochs\": \"100\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907a9df-75d9-4b1e-b65d-d7cd08b51c70",
   "metadata": {
    "collapsed": false,
    "name": "modeldeploy"
   },
   "source": [
    "# MODEL DEPLOYMENT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465650d2-213f-4dc1-ab29-39d8915d1756",
   "metadata": {
    "collapsed": false,
    "name": "modelreg"
   },
   "source": [
    "# Snowflake Model Registry - Securely manage models and their metadata in Snowflake.\n",
    "\n",
    "The model registry stores machine learning models as first-class schema-level objects in Snowflake.\n",
    "\n",
    "* Load the model produced by trainer \n",
    "* Define custom wrapper for the PyTorch model\n",
    "* Save it to Model Registry by specifying the model_name,version_name,input dataframe as signature and conda_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0a785-ed92-4363-a6e2-bfbcc057adfb",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "logmodeltoregistry_customwrapper"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN_ResNet50_FPN_Weights\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "import base64\n",
    "df=session.table(\"training_data\").limit(1).to_pandas()\n",
    "\n",
    "first_row = df.iloc[0]  \n",
    "base64_image = first_row['IMAGE_DATA'] \n",
    "df = pd.DataFrame({'IMAGE_DATA': [base64_image]})  \n",
    "\n",
    "spdf=session.create_dataframe(df)\n",
    "# Function to load the model\n",
    "def load_model(model_path):  \n",
    "    weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT  \n",
    "    model = fasterrcnn_resnet50_fpn(weights=weights)  \n",
    "    \n",
    "    # Modify the box predictor for your specific dataset\n",
    "    num_classes = 6  # Background + 5 classes\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features  \n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)  \n",
    "    model.load_state_dict(torch.load(model_path), strict=False)  \n",
    "    model.double()\n",
    "    model.eval()  \n",
    "    return model  \n",
    "\n",
    "# Function to decode and transform an image\n",
    "def decode_and_transform_image(base64_image):  \n",
    "    image_data = base64.b64decode(base64_image)  \n",
    "    image = Image.open(io.BytesIO(image_data)).convert('RGB')  \n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    # Define the necessary transformations\n",
    "    transform = transforms.Compose([  \n",
    "        transforms.Resize((224, 224)), \n",
    "        transforms.ToTensor(),  # Converts to [C, H, W]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "    ])  \n",
    "    image_tensor = transform(image)\n",
    "    image_tensor = image_tensor.double()\n",
    "    \n",
    "    # Debugging: Print the shape after transformation\n",
    "    print(f\"Shape after transformation: {image_tensor.shape}\")\n",
    "    \n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "# try:\n",
    "model_path = '/tmp/models/detectionmodel.pt'\n",
    "model = load_model(model_path)\n",
    "\n",
    "from snowflake.ml.model import custom_model\n",
    "\n",
    "class DefectDetectionModel(custom_model.CustomModel):\n",
    "    def __init__(self, context: custom_model.ModelContext) -> None:\n",
    "        super().__init__(context)\n",
    "\n",
    "    @custom_model.inference_api\n",
    "    def predict(self, input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        processed_input = torch.stack(input_df['IMAGE_DATA'].apply(decode_and_transform_image).to_list())\n",
    "        raw_output = self.context.model_ref(\"rcnn\").forward(processed_input)\n",
    "        final_output = pd.DataFrame({\"output\": [json.dumps({k: v.detach().cpu().numpy().tolist() for k, v in res.items()}) for res in raw_output]})\n",
    "        return final_output\n",
    "\n",
    "ddm = DefectDetectionModel(context = custom_model.ModelContext(models={'rcnn': model}))\n",
    "\n",
    "\n",
    "ml_reg = Registry(session=session)  \n",
    "# Log the model with the sample input for Snowflake registry\n",
    "mv = ml_reg.log_model(  \n",
    "    ddm,  \n",
    "    model_name=\"DefectDetectionModel\",  \n",
    "    version_name='v3',  \n",
    "    sample_input_data=spdf,\n",
    "    conda_dependencies=[\"pytorch\", \"torchvision\"],\n",
    "    options={\"embed_local_ml_library\": True,\n",
    "             \n",
    "                \"relax\": True}\n",
    "\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240369f3-e766-453f-acbe-245c8d0a444f",
   "metadata": {
    "collapsed": false,
    "name": "mk3"
   },
   "source": [
    "## Fetch the logged Model from Snowflake Registry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d32ac1-da76-4f35-be25-46fd63747aee",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "registry_init"
   },
   "outputs": [],
   "source": [
    "# Usage Example\n",
    "reg = Registry(session=session) \n",
    "model_ref = reg.show_models()\n",
    "model_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb44e09-e1e1-42f5-9792-9a070713a310",
   "metadata": {
    "collapsed": false,
    "name": "mk4"
   },
   "source": [
    "## Detect Defects on Validation dataset\n",
    "Lets consider there is a validation table VAL_IMAGES_LABELS which contains the Base64 Encoding information of validation images.\n",
    "\n",
    "* Get a reference to a specific model from the registry by name using the registry’s get_model method\n",
    "* Get a reference to a specific version of a model as a ModelVersion instance using the model’s version method.\n",
    "* Carry inference using the model and output the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4235d30-0724-4d7b-875b-b7403fe933c3",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "perform_inference"
   },
   "outputs": [],
   "source": [
    "\n",
    "m = reg.get_model(\"DEFECTDETECTIONMODEL\")\n",
    "mv = m.version(\"GENTLE_DONKEY_4\")\n",
    "\n",
    "\n",
    "df=session.table(\"VAL_IMAGES_LABELS\").limit(1).to_pandas()\n",
    "\n",
    "first_row = df.iloc[0]\n",
    "base64_image = first_row['IMAGE_DATA'] \n",
    "image_data_df = pd.DataFrame({'IMAGE_DATA': [base64_image]})  \n",
    "image_data_df.head()\n",
    "\n",
    "\n",
    "\n",
    "remote_prediction = mv.run(image_data_df, function_name=\"predict\")\n",
    "remote_prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1171d107-c228-4d7b-8cbb-d92469c83c69",
   "metadata": {
    "collapsed": false,
    "name": "displayimage"
   },
   "source": [
    "Fetch predictions and use a function display_image_with_boxes() to display Image with Bounding Boxes and Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92228f7-74bc-45fc-8c18-c8db544f919b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "visualize_defects"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Class mapping dictionary\n",
    "classes_la = {\n",
    "    0: \"open\",\n",
    "    1: \"short\",\n",
    "    2: \"mousebite\",\n",
    "    3: \"spur\",\n",
    "    4: \"copper\",\n",
    "    5: \"pin-hole\"\n",
    "}\n",
    "\n",
    "# Function to display the image with bounding boxes and class labels\n",
    "def display_image_with_boxes(image, boxes, labels, scores, target_size=(800, 600)):\n",
    "    # Resize the image to a target size\n",
    "    img = image.resize(target_size).convert(\"RGB\")  # Resize and convert to RGB\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Adjust the DPI and figure size\n",
    "    fig, ax = plt.subplots(figsize=(3, 6), dpi=10)  # Adjust figure size and DPI\n",
    "    ax.imshow(img_np)\n",
    "\n",
    "    for label, box, score in zip(labels, boxes, scores):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        class_label = classes_la[label]\n",
    "\n",
    "        # Create a Rectangle patch\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.text(xmin, ymin, f\"{class_label}: {score:.2f}\", verticalalignment='top', color='red', fontsize=13, weight='bold')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Ensure no padding/margins around the image\n",
    "    plt.show()\n",
    "\n",
    "# Combine the image data and remote prediction DataFrames\n",
    "combined_df = pd.concat([image_data_df, remote_prediction], axis=1)\n",
    "\n",
    "# Create a list to store data for the final DataFrame\n",
    "rows = []\n",
    "\n",
    "# Iterate through each row in the combined DataFrame\n",
    "for index, row in combined_df.iterrows():\n",
    "    output_str = row.get('output', None)  # Get the output column value\n",
    "\n",
    "    if isinstance(output_str, str):  # Ensure it's a valid string before loading as JSON\n",
    "        try:\n",
    "            # Convert the 'output' column JSON string into a dictionary\n",
    "            output_data = json.loads(output_str)\n",
    "\n",
    "            # Extract boxes, labels, and scores from JSON data\n",
    "            if 'boxes' in output_data and 'labels' in output_data and 'scores' in output_data:\n",
    "                boxes = output_data['boxes']\n",
    "                labels = output_data['labels']\n",
    "                scores = output_data['scores']\n",
    "\n",
    "                # Decode the image data\n",
    "                image_data = base64.b64decode(row['IMAGE_DATA'])\n",
    "                image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "\n",
    "                # Limit to top 5 classes based on scores\n",
    "                if len(scores) > 0:\n",
    "                    # Create a DataFrame to manage boxes, labels, and scores\n",
    "                    data = pd.DataFrame({\n",
    "                        'box': boxes,\n",
    "                        'label': labels,\n",
    "                        'score': scores\n",
    "                    })\n",
    "\n",
    "                    # Get the top 5 entries based on scores\n",
    "                    top_classes = data.nlargest(5, 'score')\n",
    "\n",
    "                    # Extract corresponding boxes, labels, and scores\n",
    "                    top_boxes = top_classes['box'].tolist()\n",
    "                    top_labels = top_classes['label'].tolist()\n",
    "                    top_scores = top_classes['score'].tolist()\n",
    "\n",
    "                    # Store each of the top 5 predictions as a separate row\n",
    "                    for i in range(len(top_boxes)):\n",
    "                        rows.append({\n",
    "                            'image_data': row['IMAGE_DATA'],\n",
    "                            'output': row['output'],\n",
    "                            'label': top_labels[i],\n",
    "                            'box': top_boxes[i],\n",
    "                            'score': top_scores[i]\n",
    "                        })\n",
    "\n",
    "                    # Display the image with bounding boxes and labels\n",
    "                    display_image_with_boxes(image, top_boxes, top_labels, top_scores)\n",
    "                else:\n",
    "                    print(\"No scores available to limit to top 5.\")\n",
    "            else:\n",
    "                print(\"Missing keys 'boxes', 'labels', or 'scores' in the output data.\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Invalid JSON in row {index}, skipping this row.\")\n",
    "    else:\n",
    "        print(f\"Invalid output type (not a string) in row {index}, skipping this row.\")\n",
    "\n",
    "# Create the final DataFrame with the collected rows (one row per label/box/score)\n",
    "final_df = pd.DataFrame(rows)\n",
    "session.sql(\"create TABLE if not exists PCB_DATASET.PUBLIC.DETECTION_OUTPUTS (\\\n",
    "\timage_data VARCHAR(16777216),\\\n",
    "\toutput VARCHAR(16777216),\\\n",
    "\tlabel NUMBER(38,0),\\\n",
    "\tbox VARIANT,\\\n",
    "\tscore FLOAT\\\n",
    ")\").collect()\n",
    "\n",
    "# Write the DataFrame to the Snowflake table\n",
    "combined_spdf = session.create_dataframe(final_df)\n",
    "combined_spdf.write.save_as_table(\"DETECTION_OUTPUTS\", mode=\"overwrite\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
